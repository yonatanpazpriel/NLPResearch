{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3599d30-639d-4a98-a5f8-9d060132b526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the CSV file\n",
    "\n",
    "\n",
    "df1, df2, df3 = pd.read_csv(text_1_path), pd.read_csv(text_2_path), pd.read_csv(text_3_path)\n",
    "df4, df5, df6 = pd.read_csv(text_4_path), pd.read_csv(text_5_path), pd.read_csv(text_6_path)\n",
    "\n",
    "dataprev = pd.concat([df1, df2, df3, df4, df5, df6], ignore_index=True)\n",
    "data = pd.read_csv(\"csv files/all_files.csv\")\n",
    "# Ensure the necessary column exists\n",
    "if \"text\" not in data.columns:\n",
    "    raise ValueError(\"The column 'preprocessed_text' is missing from the CSV file.\")\n",
    "    \n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "220726b2-91a9-4ed4-9c6b-28922fd9001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 files have >= 1 duplicate at threshold: 0.98\n",
      "Number of selected files: 77 out of 10209 pairs.\n",
      "Number of files once duplicates were removed: 6607.\n",
      "Originally 6850 files.\n"
     ]
    }
   ],
   "source": [
    "thresholdLowerBound = 0.98  # Adjust this as needed\n",
    "thresholdUpperBound = 1 # Adjust this as needed\n",
    "\n",
    "# Initialize a set to keep selected files\n",
    "selected_files = set()\n",
    "\n",
    "# Keep track of files already represented\n",
    "represented_files = set()\n",
    "\n",
    "# Sort similar pairs to ensure consistent results\n",
    "similar_pairs_sorted = sorted(similar_pairs, key=lambda x: -x[2])  # Sort by similarity score descending\n",
    "\n",
    "for file1, file2, score in similar_pairs_sorted:\n",
    "        # If neither file is already represented, add one of them\n",
    "    if file1 not in represented_files and file2 not in represented_files:\n",
    "        selected_files.add(file1)  # Arbitrarily choose file1\n",
    "    represented_files.add(file1)\n",
    "    represented_files.add(file2)    \n",
    "\n",
    "# Display results\n",
    "uniqueFiles = set(file for file in fileNames if file not in represented_files)\n",
    "print(len(represented_files), f\"files have >= 1 duplicate at threshold: {thresholdLowerBound}\")\n",
    "duplicatesRemoved = selected_files.union(uniqueFiles)\n",
    "filesToRemove = set(file for file in fileNames if file not in duplicatesRemoved)\n",
    "\n",
    "assert duplicate_files.issubset(represented_files), \"Not all duplicates are represented!\"\n",
    "assert selected_files.issubset(represented_files), \"Selected files are not correctly represented!\"\n",
    "\n",
    "print(f\"Number of selected files: {len(selected_files)} out of {len(similar_pairs_sorted)} pairs.\\n\"+\n",
    "      f\"Number of files once duplicates were removed: {len(duplicatesRemoved)}.\\n\"+\n",
    "      f\"Originally {len(data)} files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "900550ad-5bb9-40c1-a2a3-ab08d171d148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 320 files with a duplicate. There are 6530 unique files.\n",
      "\n",
      "There are 10209 pairs of files with similarity above 0.98 and below 1 out of 6850 total files:\n",
      "\n",
      "6530\n"
     ]
    }
   ],
   "source": [
    "similar_pairs = [] # store file pairs with similarity above the threshold\n",
    "\n",
    "mask = (similarity_matrix > thresholdLowerBound) & (similarity_matrix < thresholdUpperBound) # Mask similarity matrix to find pairs above threshold\n",
    "indices = np.argwhere(mask)\n",
    "fileNames = data[\"file_name\"].to_numpy()\n",
    "\n",
    "similar_pairs = [(fileNames[i], fileNames[j], similarity_matrix[i, j]) # Collect file names for pairs\n",
    "                 for i, j in indices if i < j]  # Only upper triangle, since similarityMatrix is symmetrical (i.e. sm[i,j] = sm[j,i])\n",
    "\n",
    "duplicate_files = set(file1 for file1, file2, _ in similar_pairs).union(file2 for file1, file2, _ in similar_pairs)\n",
    "print(f\"There are {len(duplicate_files)} files with a duplicate. There are {len(fileNames) -len(duplicate_files)} unique files.\\n\")\n",
    "\n",
    "# Display the results\n",
    "print(f\"There are {len(similar_pairs)} pairs of files with similarity above {thresholdLowerBound} and below {thresholdUpperBound} out of {len(data)} total files:\\n\")\n",
    "\n",
    "uniqueFiles = set(file for file in fileNames if file not in duplicate_files)\n",
    "print(len(uniqueFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ce9a6-2057-49e8-af29-acb8df932e52",
   "metadata": {},
   "source": [
    "### Below is the final dataset with one copy of each duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f036915d-a474-40e8-a02f-c0e6aad5e372",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataNoDuplicates = data[~data['file_name'].isin(filesToRemove)].reset_index(drop=True)\n",
    "dataNoDuplicates.to_csv('uniqueDataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388955c0-1dd6-46ed-8074-1c845d3a8518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
